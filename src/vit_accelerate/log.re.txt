W1101 18:21:58.884383  4364 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2
W1101 18:21:58.888578  4364 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.
============aaaaaaaaa==============
start training...
----- Training Epoch [1/200]:
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/distributed/parallel.py:159: UserWarning: Currently not a parallel execution environment, `paddle.distributed.init_parallel_env` will not do anything.
  "Currently not a parallel execution environment, `paddle.distributed.init_parallel_env` will not do anything."
debug VIT start
debug 1
debug 2
[16, 196, 768]
[1, 1, 768]
[16, 1, 768]
[1, 197, 768]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
=====================profiler step()===============================
debug VIT start
debug 1
debug 2
[16, 196, 768]
[1, 1, 768]
[16, 1, 768]
[1, 197, 768]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
Found inf or nan, current scale is: 1024.0, decrease to: 1024.0*0.5
=====================profiler step()===============================
debug VIT start
debug 1
debug 2
[16, 196, 768]
[1, 1, 768]
[16, 1, 768]
[1, 197, 768]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
=====================profiler step()===============================
debug VIT start
debug 1
debug 2
[16, 196, 768]
[1, 1, 768]
[16, 1, 768]
[1, 197, 768]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
Found inf or nan, current scale is: 512.0, decrease to: 512.0*0.5
=====================profiler step()===============================
debug VIT start
debug 1
debug 2
[16, 196, 768]
[1, 1, 768]
[16, 1, 768]
[1, 197, 768]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
=====================profiler step()===============================
debug VIT start
debug 1
debug 2
[16, 196, 768]
[1, 1, 768]
[16, 1, 768]
[1, 197, 768]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
Found inf or nan, current scale is: 256.0, decrease to: 256.0*0.5
=====================profiler step()===============================
debug VIT start
debug 1
debug 2
[16, 196, 768]
[1, 1, 768]
[16, 1, 768]
[1, 197, 768]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
=====================profiler step()===============================
debug VIT start
debug 1
debug 2
[16, 196, 768]
[1, 1, 768]
[16, 1, 768]
[1, 197, 768]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
Found inf or nan, current scale is: 128.0, decrease to: 128.0*0.5
=====================profiler step()===============================
debug VIT start
debug 1
debug 2
[16, 196, 768]
[1, 1, 768]
[16, 1, 768]
[1, 197, 768]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
=====================profiler step()===============================
debug VIT start
debug 1
debug 2
[16, 196, 768]
[1, 1, 768]
[16, 1, 768]
[1, 197, 768]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
Found inf or nan, current scale is: 64.0, decrease to: 64.0*0.5
=====================profiler step()===============================
debug VIT start
debug 1
debug 2
[16, 196, 768]
[1, 1, 768]
[16, 1, 768]
[1, 197, 768]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
=====================profiler step()===============================
----- Batch[10/3125], Loss: nan, Acc@1: 0.0057
debug VIT start
debug 1
debug 2
[16, 196, 768]
[1, 1, 768]
[16, 1, 768]
[1, 197, 768]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
Found inf or nan, current scale is: 32.0, decrease to: 32.0*0.5
=====================profiler step()===============================
debug VIT start
debug 1
debug 2
[16, 196, 768]
[1, 1, 768]
[16, 1, 768]
[1, 197, 768]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]I1101 18:22:10.956919  4364 chrometracing_logger.cc:48] writing profiling data to ./lop12/host_jupyter-1543075-4873070pid_4364_time_2022_11_01_18_22_10_951716.paddle_trace.json

[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
=====================profiler step()===============================
debug VIT start
debug 1
debug 2
[16, 196, 768]
[1, 1, 768]
[16, 1, 768]
[1, 197, 768]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
Found inf or nan, current scale is: 16.0, decrease to: 16.0*0.5
=====================profiler step()===============================
=============my_on_trace_ready===============
-------------------Device Summary-------------------
------------------------------  --------------------  
Device                          Utilization (%)       
------------------------------  --------------------  
CPU(Process)                    101.61                
CPU(System)                     8.55                  
GPU0                            53.94                 
------------------------------  --------------------  
Note:
CPU(Process) Utilization = Current process CPU time over all cpu cores / elapsed time, so max utilization can be reached 100% * number of cpu cores.
CPU(System) Utilization = All processes CPU time over all cpu cores(busy time) / (busy time + idle time).
GPU Utilization = Current process GPU time / elapsed time.
----------------------------------------------------


---------------------------------------------Overview Summary---------------------------------------------
Time unit: ms
-------------------------  -------------------------  -------------------------  -------------------------  
Event Type                 Calls                      CPU Time                   Ratio (%)                  
-------------------------  -------------------------  -------------------------  -------------------------  
ProfileStep                11                         523.81                     100.00                     
  Operator                 4384                       341.37                     65.17                      
  Forward                  22                         260.65                     49.76                      
  OperatorInner            11029                      222.03                     42.39                      
  Backward                 11                         161.86                     30.90                      
  CudaRuntime              22642                      155.52                     29.69                      
  UserDefined              298                        116.59                     22.26                      
  Dataloader               11                         2.80                       0.53                       
-------------------------  -------------------------  -------------------------  -------------------------  
                           Calls                      GPU Time                   Ratio (%)                  
-------------------------  -------------------------  -------------------------  -------------------------  
  Kernel                   4725                       282.52                     53.94                      
  Memcpy                   287                        17.50                      3.34                       
  Memset                   429                        1.12                       0.21                       
-------------------------  -------------------------  -------------------------  -------------------------  
Note:
In this table, We sum up all collected events in terms of event type.
The time of events collected on host are presented as CPU Time, and as GPU Time if on device.
Events with different types may overlap or inclusion, e.g. Operator includes OperatorInner, so the sum of ratios is not 100%.
The time of events in the same type with overlap will not calculate twice, and all time is summed after merged.
Example:
Thread 1:
  Operator: |___________|     |__________|
Thread 2:
  Operator:   |____________|     |___|
After merged:
  Result:   |______________|  |__________|

----------------------------------------------------------------------------------------------------------


-----------------------------------------------Model Summary-----------------------------------------------
Time unit: ms
---------------  ------  ----------------------------------------  ----------------------------------------  
Name             Calls   CPU Total / Avg / Max / Min / Ratio(%)    GPU Total / Avg / Max / Min / Ratio(%)    
---------------  ------  ----------------------------------------  ----------------------------------------  
ProfileStep      11      523.81 / 47.62 / 57.31 / 43.13 / 100.00   282.52 / 25.68 / 27.59 / 24.50 / 100.00   
  Dataloader     11      2.80 / 0.25 / 0.96 / 0.18 / 0.53          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  Forward        22      260.65 / 11.85 / 22.18 / 1.83 / 49.76     101.80 / 4.63 / 9.83 / 0.06 / 38.96       
  Backward       11      161.86 / 14.71 / 28.09 / 11.37 / 30.90    175.88 / 15.99 / 17.26 / 15.26 / 59.38    
  Others         -       98.50 / - / - / - / 18.81                 4.99 / - / - / - / 1.66                   
---------------  ------  ----------------------------------------  ----------------------------------------  
Note:
In this table, GPU time is the sum of all device(GPU) events called in the phase.
Unlike overview summary, if two device(GPU) events execute on different streams with overlap time, we sum them directly here.

-----------------------------------------------------------------------------------------------------------


----------------------------------------------------------------Operator Summary----------------------------------------------------------------
Time unit: ms
----------------------------------------------------  ------  ----------------------------------------  ----------------------------------------  
Name                                                  Calls   CPU Total / Avg / Max / Min / Ratio(%)    GPU Total / Avg / Max / Min / Ratio(%)    
----------------------------------------------------  ------  ----------------------------------------  ----------------------------------------  
-----------------------------------------------------------Thread: All threads merged-----------------------------------------------------------
matmul_v2_grad grad_node                              341     66.99 / 0.20 / 16.19 / 0.08 / 24.53       133.12 / 0.39 / 0.73 / 0.03 / 55.24       
  infer_shape                                         341     1.69 / 0.00 / 0.01 / 0.00 / 2.52          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             341     58.80 / 0.17 / 16.15 / 0.06 / 87.78       133.12 / 0.39 / 0.73 / 0.03 / 100.00      
    MEMSET                                            330     - / - / - / - / -                         0.62 / 0.00 / 0.00 / 0.00 / 0.46          
    volta_fp16_s884gemm_fp16_128x128_ldg8_f2f_sta...  165     - / - / - / - / -                         30.11 / 0.18 / 0.22 / 0.15 / 22.62        
    volta_fp16_s884gemm_fp16_128x128_ldg8_f2f_sta...  220     - / - / - / - / -                         31.16 / 0.14 / 0.20 / 0.05 / 23.41        
    void cutlass::Kernel<cutlass_70_wmma_tensorop...  55      - / - / - / - / -                         16.94 / 0.31 / 0.34 / 0.29 / 12.73        
    void cutlass::Kernel<cutlass_70_wmma_tensorop...  110     - / - / - / - / -                         38.44 / 0.35 / 0.39 / 0.33 / 28.87        
    void cutlass::Kernel<cutlass_70_wmma_tensorop...  55      - / - / - / - / -                         12.38 / 0.23 / 0.25 / 0.21 / 9.30         
    volta_fp16_s884gemm_fp16_256x128_ldg8_f2f_tn      55      - / - / - / - / -                         3.17 / 0.06 / 0.06 / 0.05 / 2.38          
    void cutlass::Kernel<cutlass_70_wmma_tensorop...  11      - / - / - / - / -                         0.12 / 0.01 / 0.01 / 0.01 / 0.09          
    void splitKreduce_kernel<float, __half, float...  11      - / - / - / - / -                         0.06 / 0.01 / 0.01 / 0.00 / 0.04          
    volta_fp16_s884gemm_fp16_64x64_ldg8_f2f_nt        11      - / - / - / - / -                         0.13 / 0.01 / 0.01 / 0.01 / 0.10          
cast                                                  594     44.89 / 0.08 / 1.53 / 0.02 / 16.44        23.14 / 0.04 / 1.43 / 0.00 / 9.60         
  infer_shape                                         594     0.70 / 0.00 / 0.02 / 0.00 / 1.55          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             594     14.20 / 0.02 / 0.08 / 0.01 / 31.64        7.87 / 0.01 / 0.03 / 0.00 / 34.00         
    void phi::funcs::VectorizedElementwiseKernel<...  77      - / - / - / - / -                         1.50 / 0.02 / 0.02 / 0.00 / 19.12         
    void phi::funcs::VectorizedElementwiseKernel<...  11      - / - / - / - / -                         0.04 / 0.00 / 0.00 / 0.00 / 0.51          
    void phi::funcs::VectorizedElementwiseKernel<...  506     - / - / - / - / -                         6.32 / 0.01 / 0.03 / 0.00 / 80.37         
  grad_node_creation                                  594     5.09 / 0.01 / 0.07 / 0.00 / 11.34         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  GpuMemcpySync:CUDAPinned->GPU                       11      15.67 / 1.42 / 1.44 / 1.41 / 34.91        15.27 / 1.39 / 1.40 / 1.37 / 66.00        
    MEMCPY_HtoD                                       11      - / - / - / - / -                         15.27 / 1.39 / 1.40 / 1.37 / 100.00       
matmul_v2                                             55      6.06 / 0.11 / 0.29 / 0.09 / 2.22          12.37 / 0.22 / 0.25 / 0.21 / 5.13         
  infer_shape                                         55      0.28 / 0.01 / 0.02 / 0.00 / 4.54          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             55      4.04 / 0.07 / 0.24 / 0.06 / 66.70         12.37 / 0.22 / 0.25 / 0.21 / 100.00       
    void cutlass::Kernel<cutlass_70_wmma_tensorop...  55      - / - / - / - / -                         12.37 / 0.22 / 0.25 / 0.21 / 100.00       
  grad_node_creation                                  55      0.57 / 0.01 / 0.02 / 0.01 / 9.38          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
layer_norm_grad grad_node                             121     12.19 / 0.10 / 0.15 / 0.08 / 4.47         9.41 / 0.08 / 0.08 / 0.06 / 3.90          
  infer_shape                                         121     0.47 / 0.00 / 0.03 / 0.00 / 3.82          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             121     5.63 / 0.05 / 0.08 / 0.04 / 46.14         6.71 / 0.06 / 0.06 / 0.05 / 71.31         
    void paddle::operators::LayerNormBackwardPart...  121     - / - / - / - / -                         3.20 / 0.03 / 0.03 / 0.02 / 47.65         
    void paddle::operators::LayerNormBackwardSumG...  121     - / - / - / - / -                         0.55 / 0.00 / 0.01 / 0.00 / 8.15          
    void paddle::operators::LayerNormBackwardComp...  121     - / - / - / - / -                         2.97 / 0.02 / 0.03 / 0.02 / 44.20         
  void Eigen::internal::EigenMetaKernel<Eigen::Te...  110     - / - / - / - / -                         2.70 / 0.02 / 0.03 / 0.02 / 28.69         
elementwise_add_grad grad_node                        297     16.98 / 0.06 / 0.18 / 0.04 / 6.22         7.48 / 0.03 / 0.04 / 0.01 / 3.10          
  infer_shape                                         297     0.50 / 0.00 / 0.02 / 0.00 / 2.94          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             297     11.68 / 0.04 / 0.16 / 0.03 / 68.76        7.48 / 0.03 / 0.04 / 0.01 / 100.00        
    void phi::funcs::ReduceHigherDimKernel<phi::d...  187     - / - / - / - / -                         3.46 / 0.02 / 0.04 / 0.01 / 46.31         
    void phi::funcs::ReduceHigherDimKernel<phi::d...  165     - / - / - / - / -                         2.10 / 0.01 / 0.02 / 0.01 / 28.11         
cast grad_node                                        572     20.43 / 0.04 / 4.07 / 0.02 / 7.48         7.16 / 0.01 / 0.02 / 0.00 / 2.97          
  infer_shape                                         572     0.55 / 0.00 / 0.00 / 0.00 / 2.70          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             572     9.19 / 0.02 / 0.04 / 0.01 / 45.00         7.16 / 0.01 / 0.02 / 0.00 / 100.00        
    void phi::funcs::VectorizedElementwiseKernel<...  495     - / - / - / - / -                         5.69 / 0.01 / 0.02 / 0.00 / 79.50         
    void phi::funcs::VectorizedElementwiseKernel<...  77      - / - / - / - / -                         1.47 / 0.02 / 0.02 / 0.00 / 20.50         
layer_norm                                            121     11.18 / 0.09 / 0.16 / 0.08 / 4.09         5.90 / 0.05 / 0.05 / 0.05 / 2.45          
  infer_shape                                         121     0.55 / 0.00 / 0.02 / 0.00 / 4.91          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             121     3.83 / 0.03 / 0.06 / 0.03 / 34.26         5.90 / 0.05 / 0.05 / 0.05 / 100.00        
    void paddle::operators::LayerNormForward<phi:...  121     - / - / - / - / -                         5.90 / 0.05 / 0.05 / 0.05 / 100.00        
  grad_node_creation                                  121     2.28 / 0.02 / 0.08 / 0.01 / 20.44         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
gelu_grad grad_node                                   55      1.72 / 0.03 / 0.05 / 0.03 / 0.63          5.34 / 0.10 / 0.11 / 0.09 / 2.21          
  infer_shape                                         55      0.10 / 0.00 / 0.00 / 0.00 / 5.53          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             55      0.89 / 0.02 / 0.03 / 0.01 / 51.86         5.34 / 0.10 / 0.11 / 0.09 / 100.00        
    void phi::funcs::VectorizedElementwiseKernel<...  55      - / - / - / - / -                         5.34 / 0.10 / 0.11 / 0.09 / 100.00        
transpose2_grad grad_node                             231     7.80 / 0.03 / 0.22 / 0.02 / 2.86          4.84 / 0.02 / 0.02 / 0.02 / 2.01          
  infer_shape                                         231     0.35 / 0.00 / 0.00 / 0.00 / 4.47          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             231     4.40 / 0.02 / 0.20 / 0.01 / 56.44         4.84 / 0.02 / 0.02 / 0.02 / 100.00        
    void paddle::operators::TilingSwapDim1And2<ph...  11      - / - / - / - / -                         0.22 / 0.02 / 0.02 / 0.02 / 4.52          
    void Eigen::internal::EigenMetaKernel<Eigen::...  220     - / - / - / - / -                         4.62 / 0.02 / 0.02 / 0.02 / 95.48         
transpose2                                            231     12.53 / 0.05 / 0.10 / 0.04 / 4.59         4.79 / 0.02 / 0.02 / 0.02 / 1.99          
  infer_shape                                         231     0.59 / 0.00 / 0.01 / 0.00 / 4.74          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             231     5.75 / 0.02 / 0.06 / 0.02 / 45.93         4.79 / 0.02 / 0.02 / 0.02 / 100.00        
    void Eigen::internal::EigenMetaKernel<Eigen::...  220     - / - / - / - / -                         4.59 / 0.02 / 0.02 / 0.02 / 95.91         
    void paddle::operators::TilingSwapDim1And2<ph...  11      - / - / - / - / -                         0.20 / 0.02 / 0.02 / 0.02 / 4.09          
  grad_node_creation                                  231     1.67 / 0.01 / 0.03 / 0.01 / 13.31         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
check_finite_and_unscale                              11      1.91 / 0.17 / 0.19 / 0.15 / 0.70          4.52 / 0.41 / 0.42 / 0.41 / 1.87          
  infer_shape                                         11      0.38 / 0.03 / 0.04 / 0.03 / 19.71         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             11      1.09 / 0.10 / 0.11 / 0.09 / 56.82         4.52 / 0.41 / 0.42 / 0.41 / 100.00        
    void paddle::operators::InverseAndMemset<floa...  11      - / - / - / - / -                         0.04 / 0.00 / 0.00 / 0.00 / 0.93          
    void paddle::operators::CheckFiniteAndUnscale...  11      - / - / - / - / -                         4.43 / 0.40 / 0.41 / 0.40 / 98.16         
  grad_node_creation                                  11      0.02 / 0.00 / 0.00 / 0.00 / 0.98          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
conv2d_grad grad_node                                 11      13.13 / 1.19 / 1.27 / 1.12 / 4.81         4.47 / 0.41 / 0.44 / 0.39 / 1.85          
  infer_shape                                         11      0.03 / 0.00 / 0.00 / 0.00 / 0.22          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             11      12.73 / 1.16 / 1.23 / 1.09 / 96.97        4.47 / 0.41 / 0.44 / 0.39 / 100.00        
    MEMSET                                            33      - / - / - / - / -                         0.37 / 0.01 / 0.02 / 0.00 / 8.17          
    void cudnn::ops::nchwToNhwcKernel<__half, __h...  22      - / - / - / - / -                         1.07 / 0.05 / 0.09 / 0.02 / 23.87         
    void xmma_cudnn::gemm::kernel<xmma_cudnn::imp...  11      - / - / - / - / -                         2.74 / 0.25 / 0.27 / 0.24 / 61.47         
    void cudnn::ops::nhwcToNchwKernel<__half, __h...  11      - / - / - / - / -                         0.29 / 0.03 / 0.03 / 0.03 / 6.49          
gelu                                                  55      3.26 / 0.06 / 0.08 / 0.05 / 1.19          4.20 / 0.08 / 0.08 / 0.07 / 1.74          
  infer_shape                                         55      0.36 / 0.01 / 0.02 / 0.01 / 11.09         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             55      1.20 / 0.02 / 0.03 / 0.02 / 36.96         4.20 / 0.08 / 0.08 / 0.07 / 100.00        
    void phi::funcs::VectorizedElementwiseKernel<...  55      - / - / - / - / -                         4.20 / 0.08 / 0.08 / 0.07 / 100.00        
  grad_node_creation                                  55      0.48 / 0.01 / 0.01 / 0.01 / 14.75         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
concat grad_node                                      55      2.74 / 0.05 / 0.07 / 0.03 / 1.00          3.15 / 0.06 / 0.06 / 0.06 / 1.31          
  infer_shape                                         55      0.42 / 0.01 / 0.03 / 0.00 / 15.21         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             55      1.43 / 0.03 / 0.04 / 0.02 / 52.09         3.15 / 0.06 / 0.06 / 0.06 / 100.00        
    void phi::funcs::ConcatKernel_<phi::dtype::fl...  55      - / - / - / - / -                         3.15 / 0.06 / 0.06 / 0.06 / 100.00        
split                                                 55      4.47 / 0.08 / 0.11 / 0.07 / 1.64          3.13 / 0.06 / 0.06 / 0.05 / 1.30          
  infer_shape                                         55      0.31 / 0.01 / 0.02 / 0.00 / 7.03          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             55      1.74 / 0.03 / 0.05 / 0.03 / 39.05         3.13 / 0.06 / 0.06 / 0.05 / 100.00        
    void phi::funcs::SplitKernel_<phi::dtype::flo...  55      - / - / - / - / -                         3.13 / 0.06 / 0.06 / 0.05 / 100.00        
  grad_node_creation                                  55      0.81 / 0.01 / 0.04 / 0.01 / 18.16         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
elementwise_add                                       110     7.82 / 0.07 / 0.11 / 0.06 / 2.87          2.39 / 0.02 / 0.02 / 0.02 / 0.99          
  infer_shape                                         110     0.26 / 0.00 / 0.00 / 0.00 / 3.27          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             110     2.94 / 0.03 / 0.06 / 0.02 / 37.60         2.39 / 0.02 / 0.02 / 0.02 / 100.00        
    void phi::funcs::VectorizedBroadcastKernel<ph...  110     - / - / - / - / -                         2.39 / 0.02 / 0.02 / 0.02 / 100.00        
  grad_node_creation                                  110     1.45 / 0.01 / 0.03 / 0.01 / 18.47         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
softmax_grad grad_node                                55      2.22 / 0.04 / 0.06 / 0.03 / 0.81          2.32 / 0.04 / 0.04 / 0.04 / 0.96          
  infer_shape                                         55      0.26 / 0.00 / 0.01 / 0.00 / 11.88         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             55      0.99 / 0.02 / 0.03 / 0.01 / 44.68         2.32 / 0.04 / 0.04 / 0.04 / 100.00        
    void phi::WarpSoftmaxBackward<float, float, f...  55      - / - / - / - / -                         2.32 / 0.04 / 0.04 / 0.04 / 100.00        
scale                                                 61      4.19 / 0.07 / 0.09 / 0.06 / 1.53          0.79 / 0.01 / 0.01 / 0.00 / 0.33          
  infer_shape                                         61      0.48 / 0.01 / 0.02 / 0.01 / 11.47         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             61      1.69 / 0.03 / 0.05 / 0.02 / 40.40         0.79 / 0.01 / 0.01 / 0.00 / 100.00        
    void phi::funcs::VectorizedElementwiseKernel<...  6       - / - / - / - / -                         0.03 / 0.00 / 0.00 / 0.00 / 3.19          
    void phi::funcs::VectorizedElementwiseKernel<...  55      - / - / - / - / -                         0.76 / 0.01 / 0.01 / 0.01 / 96.81         
  grad_node_creation                                  61      0.57 / 0.01 / 0.03 / 0.00 / 13.71         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
scale grad_node                                       55      1.72 / 0.03 / 0.05 / 0.03 / 0.63          0.66 / 0.01 / 0.01 / 0.01 / 0.27          
  infer_shape                                         55      0.27 / 0.00 / 0.02 / 0.00 / 16.01         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             55      0.86 / 0.02 / 0.02 / 0.01 / 49.98         0.66 / 0.01 / 0.01 / 0.01 / 100.00        
    void phi::funcs::VectorizedElementwiseKernel<...  55      - / - / - / - / -                         0.66 / 0.01 / 0.01 / 0.01 / 100.00        
concat_grad grad_node                                 11      1.00 / 0.09 / 0.11 / 0.08 / 0.37          0.38 / 0.03 / 0.04 / 0.03 / 0.16          
  infer_shape                                         11      0.02 / 0.00 / 0.00 / 0.00 / 2.03          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             11      0.77 / 0.07 / 0.09 / 0.06 / 77.26         0.38 / 0.03 / 0.04 / 0.03 / 100.00        
    void phi::funcs::SplitKernel_<float>(float co...  11      - / - / - / - / -                         0.34 / 0.03 / 0.03 / 0.03 / 89.60         
slice_grad grad_node                                  11      0.63 / 0.06 / 0.09 / 0.05 / 0.23          0.20 / 0.02 / 0.02 / 0.02 / 0.08          
  infer_shape                                         11      0.02 / 0.00 / 0.00 / 0.00 / 3.71          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             11      0.31 / 0.03 / 0.04 / 0.03 / 49.55         0.20 / 0.02 / 0.02 / 0.02 / 100.00        
    void Eigen::internal::EigenMetaKernel<Eigen::...  11      - / - / - / - / -                         0.20 / 0.02 / 0.02 / 0.02 / 100.00        
accuracy                                              11      0.82 / 0.07 / 0.12 / 0.05 / 0.30          0.11 / 0.01 / 0.01 / 0.01 / 0.05          
  infer_shape                                         11      0.08 / 0.01 / 0.02 / 0.01 / 10.28         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             11      0.38 / 0.03 / 0.04 / 0.03 / 45.68         0.11 / 0.01 / 0.01 / 0.01 / 100.00        
    MEMSET                                            11      - / - / - / - / -                         0.02 / 0.00 / 0.00 / 0.00 / 18.93         
    void phi::AccuracyCudaKernel<512>(int, int, l...  11      - / - / - / - / -                         0.09 / 0.01 / 0.01 / 0.01 / 81.07         
  grad_node_creation                                  11      0.01 / 0.00 / 0.00 / 0.00 / 0.83          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
expand_v2_grad grad_node                              11      0.60 / 0.05 / 0.07 / 0.05 / 0.22          0.11 / 0.01 / 0.01 / 0.01 / 0.05          
  infer_shape                                         11      0.05 / 0.00 / 0.01 / 0.00 / 8.36          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             11      0.29 / 0.03 / 0.03 / 0.02 / 48.93         0.11 / 0.01 / 0.01 / 0.01 / 100.00        
    void Eigen::internal::EigenMetaKernel<Eigen::...  11      - / - / - / - / -                         0.11 / 0.01 / 0.01 / 0.01 / 100.00        
fill_constant                                         33      2.02 / 0.06 / 0.09 / 0.05 / 0.74          0.11 / 0.00 / 0.00 / 0.00 / 0.04          
  infer_shape                                         33      0.07 / 0.00 / 0.00 / 0.00 / 3.69          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             33      0.95 / 0.03 / 0.04 / 0.02 / 47.26         0.11 / 0.00 / 0.00 / 0.00 / 100.00        
    void phi::funcs::VectorizedElementwiseKernel<...  33      - / - / - / - / -                         0.11 / 0.00 / 0.00 / 0.00 / 100.00        
  grad_node_creation                                  33      0.01 / 0.00 / 0.00 / 0.00 / 0.32          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
elementwise_mul                                       22      1.37 / 0.06 / 0.08 / 0.05 / 0.50          0.10 / 0.00 / 0.01 / 0.00 / 0.04          
  infer_shape                                         22      0.06 / 0.00 / 0.00 / 0.00 / 4.06          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             22      0.64 / 0.03 / 0.04 / 0.02 / 46.95         0.10 / 0.00 / 0.01 / 0.00 / 100.00        
    void phi::funcs::VectorizedBroadcastKernel<fl...  11      - / - / - / - / -                         0.05 / 0.00 / 0.01 / 0.00 / 50.47         
    void phi::funcs::VectorizedBroadcastKernel<lo...  11      - / - / - / - / -                         0.05 / 0.00 / 0.00 / 0.00 / 49.53         
  grad_node_creation                                  22      0.12 / 0.01 / 0.01 / 0.00 / 9.00          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
top_k_v2                                              11      0.78 / 0.07 / 0.08 / 0.06 / 0.29          0.10 / 0.01 / 0.01 / 0.01 / 0.04          
  infer_shape                                         11      0.09 / 0.01 / 0.01 / 0.01 / 11.19         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             11      0.36 / 0.03 / 0.04 / 0.03 / 46.13         0.10 / 0.01 / 0.01 / 0.01 / 100.00        
    void paddle::operators::KeMatrixTopK<phi::dty...  11      - / - / - / - / -                         0.10 / 0.01 / 0.01 / 0.01 / 100.00        
  grad_node_creation                                  11      0.12 / 0.01 / 0.01 / 0.01 / 15.41         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
softmax                                               11      1.22 / 0.11 / 0.13 / 0.10 / 0.45          0.10 / 0.01 / 0.01 / 0.01 / 0.04          
  infer_shape                                         11      0.07 / 0.01 / 0.01 / 0.01 / 5.89          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             11      0.58 / 0.05 / 0.06 / 0.05 / 47.71         0.10 / 0.01 / 0.01 / 0.01 / 100.00        
    void cudnn::ops::softmax_fw_kernel<2, __half,...  11      - / - / - / - / -                         0.10 / 0.01 / 0.01 / 0.01 / 100.00        
  grad_node_creation                                  11      0.19 / 0.02 / 0.02 / 0.01 / 15.88         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
unsqueeze2                                            22      2.05 / 0.09 / 0.17 / 0.03 / 0.75          0.06 / 0.00 / 0.01 / 0.00 / 0.03          
  GpuMemcpySync:CUDAPinned->GPU                       11      0.50 / 0.05 / 0.06 / 0.04 / 24.48         0.02 / 0.00 / 0.00 / 0.00 / 38.08         
    MEMCPY_HtoD                                       11      - / - / - / - / -                         0.02 / 0.00 / 0.00 / 0.00 / 100.00        
  infer_shape                                         22      0.26 / 0.01 / 0.02 / 0.01 / 12.51         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             22      0.55 / 0.03 / 0.05 / 0.01 / 27.03         0.04 / 0.00 / 0.00 / 0.00 / 61.92         
  grad_node_creation                                  22      0.01 / 0.00 / 0.00 / 0.00 / 0.33          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
reduce_min                                            11      1.08 / 0.10 / 0.12 / 0.09 / 0.39          0.06 / 0.01 / 0.01 / 0.00 / 0.02          
  infer_shape                                         11      0.13 / 0.01 / 0.01 / 0.01 / 12.31         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             11      0.70 / 0.06 / 0.09 / 0.05 / 64.93         0.06 / 0.01 / 0.01 / 0.00 / 100.00        
    void cub::DeviceReduceSingleTileKernel<cub::D...  11      - / - / - / - / -                         0.06 / 0.01 / 0.01 / 0.00 / 100.00        
  grad_node_creation                                  11      0.00 / 0.00 / 0.00 / 0.00 / 0.15          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
expand_v2                                             11      0.79 / 0.07 / 0.08 / 0.07 / 0.29          0.06 / 0.01 / 0.01 / 0.00 / 0.02          
  infer_shape                                         11      0.09 / 0.01 / 0.01 / 0.01 / 10.74         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             11      0.34 / 0.03 / 0.04 / 0.03 / 42.66         0.06 / 0.01 / 0.01 / 0.00 / 100.00        
    void Eigen::internal::EigenMetaKernel<Eigen::...  11      - / - / - / - / -                         0.06 / 0.01 / 0.01 / 0.00 / 100.00        
  grad_node_creation                                  11      0.13 / 0.01 / 0.01 / 0.01 / 16.11         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
reduce_max                                            11      0.81 / 0.07 / 0.10 / 0.06 / 0.30          0.05 / 0.00 / 0.01 / 0.00 / 0.02          
  infer_shape                                         11      0.07 / 0.01 / 0.01 / 0.01 / 8.62          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             11      0.51 / 0.05 / 0.07 / 0.04 / 63.58         0.05 / 0.00 / 0.01 / 0.00 / 100.00        
    void cub::DeviceReduceSingleTileKernel<cub::D...  11      - / - / - / - / -                         0.05 / 0.00 / 0.01 / 0.00 / 100.00        
  grad_node_creation                                  11      0.00 / 0.00 / 0.00 / 0.00 / 0.21          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
not_equal                                             11      0.75 / 0.07 / 0.08 / 0.06 / 0.27          0.05 / 0.00 / 0.01 / 0.00 / 0.02          
  infer_shape                                         11      0.09 / 0.01 / 0.01 / 0.01 / 11.35         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             11      0.36 / 0.03 / 0.04 / 0.03 / 47.92         0.05 / 0.00 / 0.01 / 0.00 / 100.00        
    void phi::funcs::VectorizedBroadcastKernel<lo...  11      - / - / - / - / -                         0.05 / 0.00 / 0.01 / 0.00 / 100.00        
  grad_node_creation                                  11      0.00 / 0.00 / 0.00 / 0.00 / 0.39          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
mean                                                  11      0.93 / 0.08 / 0.10 / 0.08 / 0.34          0.05 / 0.00 / 0.01 / 0.00 / 0.02          
  infer_shape                                         11      0.06 / 0.01 / 0.01 / 0.01 / 6.74          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             11      0.54 / 0.05 / 0.06 / 0.04 / 57.67         0.05 / 0.00 / 0.01 / 0.00 / 100.00        
    void cub::DeviceReduceSingleTileKernel<cub::D...  11      - / - / - / - / -                         0.05 / 0.00 / 0.01 / 0.00 / 100.00        
  grad_node_creation                                  11      0.12 / 0.01 / 0.02 / 0.01 / 13.32         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
slice                                                 11      1.19 / 0.11 / 0.19 / 0.09 / 0.43          0.05 / 0.00 / 0.01 / 0.00 / 0.02          
  infer_shape                                         11      0.07 / 0.01 / 0.01 / 0.01 / 6.24          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             11      0.45 / 0.04 / 0.06 / 0.03 / 38.17         0.05 / 0.00 / 0.01 / 0.00 / 100.00        
    void Eigen::internal::EigenMetaKernel<Eigen::...  11      - / - / - / - / -                         0.05 / 0.00 / 0.01 / 0.00 / 100.00        
  grad_node_creation                                  11      0.24 / 0.02 / 0.11 / 0.01 / 20.16         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
elementwise_mul_grad grad_node                        11      0.80 / 0.07 / 0.08 / 0.07 / 0.29          0.05 / 0.00 / 0.01 / 0.00 / 0.02          
  infer_shape                                         11      0.03 / 0.00 / 0.00 / 0.00 / 4.30          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             11      0.47 / 0.04 / 0.05 / 0.04 / 58.25         0.05 / 0.00 / 0.01 / 0.00 / 100.00        
    void phi::funcs::VectorizedBroadcastKernel<fl...  11      - / - / - / - / -                         0.05 / 0.00 / 0.01 / 0.00 / 100.00        
less_than                                             11      0.72 / 0.07 / 0.08 / 0.06 / 0.26          0.05 / 0.00 / 0.00 / 0.00 / 0.02          
  infer_shape                                         11      0.06 / 0.01 / 0.01 / 0.01 / 8.90          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             11      0.31 / 0.03 / 0.03 / 0.03 / 42.97         0.05 / 0.00 / 0.00 / 0.00 / 100.00        
    void phi::funcs::VectorizedBroadcastKernel<lo...  11      - / - / - / - / -                         0.05 / 0.00 / 0.00 / 0.00 / 100.00        
  grad_node_creation                                  11      0.00 / 0.00 / 0.00 / 0.00 / 0.26          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
softmax_with_cross_entropy_grad grad_node             11      0.52 / 0.05 / 0.06 / 0.04 / 0.19          0.05 / 0.00 / 0.00 / 0.00 / 0.02          
  infer_shape                                         11      0.05 / 0.00 / 0.00 / 0.00 / 8.73          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             11      0.26 / 0.02 / 0.03 / 0.02 / 49.51         0.05 / 0.00 / 0.00 / 0.00 / 100.00        
    void phi::SoftmaxWithCrossEntropyGradHardLabe...  11      - / - / - / - / -                         0.05 / 0.00 / 0.00 / 0.00 / 100.00        
greater_equal                                         11      0.67 / 0.06 / 0.07 / 0.06 / 0.25          0.05 / 0.00 / 0.00 / 0.00 / 0.02          
  infer_shape                                         11      0.07 / 0.01 / 0.01 / 0.01 / 11.20         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             11      0.31 / 0.03 / 0.04 / 0.03 / 45.81         0.05 / 0.00 / 0.00 / 0.00 / 100.00        
    void phi::funcs::VectorizedBroadcastKernel<lo...  11      - / - / - / - / -                         0.05 / 0.00 / 0.00 / 0.00 / 100.00        
  grad_node_creation                                  11      0.00 / 0.00 / 0.00 / 0.00 / 0.26          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
mean_grad grad_node                                   11      0.39 / 0.04 / 0.07 / 0.03 / 0.14          0.04 / 0.00 / 0.00 / 0.00 / 0.02          
  infer_shape                                         11      0.02 / 0.00 / 0.00 / 0.00 / 4.14          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             11      0.21 / 0.02 / 0.04 / 0.02 / 54.27         0.04 / 0.00 / 0.00 / 0.00 / 100.00        
    void phi::MeanRunKernel<float>(float const*, ...  11      - / - / - / - / -                         0.04 / 0.00 / 0.00 / 0.00 / 100.00        
flatten_contiguous_range_grad grad_node               11      0.26 / 0.02 / 0.03 / 0.02 / 0.10          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  infer_shape                                         11      0.04 / 0.00 / 0.00 / 0.00 / 15.90         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             11      0.04 / 0.00 / 0.00 / 0.00 / 15.23         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
reshape2_grad grad_node                               220     3.32 / 0.02 / 0.05 / 0.01 / 1.22          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  infer_shape                                         220     0.40 / 0.00 / 0.02 / 0.00 / 11.95         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             220     0.46 / 0.00 / 0.03 / 0.00 / 13.86         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
reshape2                                              220     7.51 / 0.03 / 0.06 / 0.03 / 2.75          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  infer_shape                                         220     0.81 / 0.00 / 0.01 / 0.00 / 10.76         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             220     0.92 / 0.00 / 0.02 / 0.00 / 12.29         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  grad_node_creation                                  220     1.49 / 0.01 / 0.02 / 0.00 / 19.80         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
flatten_contiguous_range                              11      0.61 / 0.06 / 0.07 / 0.05 / 0.22          0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  infer_shape                                         11      0.08 / 0.01 / 0.01 / 0.01 / 12.84         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  compute                                             11      0.07 / 0.01 / 0.01 / 0.01 / 11.17         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
  grad_node_creation                                  11      0.08 / 0.01 / 0.01 / 0.01 / 13.74         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
----------------------------------------------------  ------  ----------------------------------------  ----------------------------------------  


---------------------------------------------------------------Kernel Summary---------------------------------------------------------------
Time unit: ms
------------------------------------------------------------------------------------------  ------  ----------------------------------------  
Name                                                                                        Calls   GPU Total / Avg / Max / Min / Ratio(%)    
------------------------------------------------------------------------------------------  ------  ----------------------------------------  
void cutlass::Kernel<cutlass_70_wmma_tensorop_h161616gemm_16x16_32x1_nt_align1>             110     38.44 / 0.35 / 0.39 / 0.33 / 13.61        
void cutlass::Kernel<cutlass_70_wmma_tensorop_h161616gemm_16x16_32x1_nn_align1>             110     34.02 / 0.31 / 0.34 / 0.29 / 12.04        
volta_fp16_s884gemm_fp16_128x128_ldg8_f2f_stages_32x1_nt                                    220     31.16 / 0.14 / 0.20 / 0.05 / 11.03        
volta_fp16_s884gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn                                    165     30.11 / 0.18 / 0.22 / 0.15 / 10.66        
volta_fp16_s884gemm_fp16_256x128_ldg8_f2f_nn                                                165     28.71 / 0.17 / 0.21 / 0.13 / 10.16        
void cutlass::Kernel<cutlass_70_wmma_tensorop_h161616gemm_16x16_32x1_tn_align1>             110     24.75 / 0.22 / 0.25 / 0.21 / 8.76         
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eige...  440     9.22 / 0.02 / 0.02 / 0.02 / 3.26          
void phi::funcs::VectorizedElementwiseKernel<phi::dtype::float16, phi::CastFuctor<float...  583     7.79 / 0.01 / 0.03 / 0.00 / 2.76          
void phi::funcs::VectorizedBroadcastKernel<phi::dtype::float16, phi::dtype::float16, ph...  297     7.41 / 0.02 / 0.06 / 0.01 / 2.62          
void phi::funcs::VectorizedElementwiseKernel<float, phi::CastFuctor<phi::dtype::float16...  572     7.20 / 0.01 / 0.02 / 0.00 / 2.55          
void paddle::operators::LayerNormForward<phi::dtype::float16, float, 512, false>            121     5.90 / 0.05 / 0.05 / 0.05 / 2.09          
void phi::funcs::VectorizedElementwiseKernel<phi::dtype::float16, phi::GeluWithoutAppro...  55      5.34 / 0.10 / 0.11 / 0.09 / 1.89          
void paddle::operators::CheckFiniteAndUnscale<float, float>                                 11      4.43 / 0.40 / 0.41 / 0.40 / 1.57          
void phi::funcs::VectorizedElementwiseKernel<phi::dtype::float16, phi::GeluWithoutAppro...  55      4.20 / 0.08 / 0.08 / 0.07 / 1.49          
volta_fp16_scudnn_fp16_128x64_relu_xregs_large_nn_v1                                        11      3.62 / 0.33 / 0.38 / 0.30 / 1.28          
void phi::funcs::ReduceHigherDimKernel<phi::dtype::float16, phi::dtype::float16, float,...  187     3.46 / 0.02 / 0.04 / 0.01 / 1.23          
void paddle::operators::LayerNormBackwardPartGradGammaBeta<phi::dtype::float16, float, ...  121     3.20 / 0.03 / 0.03 / 0.02 / 1.13          
volta_fp16_s884gemm_fp16_256x128_ldg8_f2f_tn                                                55      3.17 / 0.06 / 0.06 / 0.05 / 1.12          
void phi::funcs::ConcatKernel_<phi::dtype::float16>                                         55      3.15 / 0.06 / 0.06 / 0.06 / 1.12          
void phi::funcs::SplitKernel_<phi::dtype::float16>                                          55      3.13 / 0.06 / 0.06 / 0.05 / 1.11          
volta_fp16_s884gemm_fp16_128x128_ldg8_f2f_nn                                                55      2.99 / 0.05 / 0.06 / 0.05 / 1.06          
void paddle::operators::LayerNormBackwardComputeGradInput<phi::dtype::float16, float, 3...  121     2.97 / 0.02 / 0.03 / 0.02 / 1.05          
void xmma_cudnn::gemm::kernel<xmma_cudnn::implicit_gemm::wgrad_indexed::Kernel_traits<x...  11      2.74 / 0.25 / 0.27 / 0.24 / 0.97          
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eige...  110     2.70 / 0.02 / 0.03 / 0.02 / 0.96          
void phi::WarpSoftmaxBackward<float, float, float, 8, false>                                55      2.32 / 0.04 / 0.04 / 0.04 / 0.82          
void phi::funcs::ReduceHigherDimKernel<phi::dtype::float16, phi::dtype::float16, float,...  165     2.10 / 0.01 / 0.02 / 0.01 / 0.74          
void phi::WarpSoftmaxForward<float, float, float, 8, false>                                 55      1.75 / 0.03 / 0.03 / 0.03 / 0.62          
void phi::funcs::VectorizedElementwiseKernel<phi::dtype::float16, phi::ScaleFunctor<phi...  110     1.42 / 0.01 / 0.01 / 0.01 / 0.50          
void cudnn::ops::nchwToNhwcKernel<__half, __half, float, false, true, (cudnnKernelDataT...  22      1.07 / 0.05 / 0.09 / 0.02 / 0.38          
void paddle::operators::LayerNormBackwardSumGradGammaBeta<phi::dtype::float16, float, 3...  121     0.55 / 0.00 / 0.01 / 0.00 / 0.19          
void paddle::operators::TilingSwapDim1And2<phi::dtype::float16, 256, 32, 32>                22      0.41 / 0.02 / 0.02 / 0.02 / 0.15          
void phi::funcs::SplitKernel_<float>                                                        11      0.34 / 0.03 / 0.03 / 0.03 / 0.12          
void phi::funcs::ConcatKernel_<float>                                                       11      0.34 / 0.03 / 0.03 / 0.03 / 0.12          
void cudnn::ops::nhwcToNchwKernel<__half, __half, float, true, false, (cudnnKernelDataT...  11      0.29 / 0.03 / 0.03 / 0.03 / 0.10          
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eige...  11      0.20 / 0.02 / 0.02 / 0.02 / 0.07          
volta_fp16_s884gemm_fp16_64x64_ldg8_f2f_nt                                                  11      0.13 / 0.01 / 0.01 / 0.01 / 0.04          
void cutlass::Kernel<cutlass_70_wmma_tensorop_f16_s161616gemm_f16_32x32_64x2_nn_align8>     11      0.12 / 0.01 / 0.01 / 0.01 / 0.04          
void cutlass::Kernel<cutlass_70_wmma_tensorop_s161616gemm_f16_32x32_64x2_tn_align8>         11      0.12 / 0.01 / 0.01 / 0.01 / 0.04          
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eige...  11      0.11 / 0.01 / 0.01 / 0.01 / 0.04          
void phi::funcs::VectorizedElementwiseKernel<long, phi::FullFuctor<long, long>, 0, 1, 2>    33      0.11 / 0.00 / 0.00 / 0.00 / 0.04          
void paddle::operators::KeMatrixTopK<phi::dtype::float16, 5, 256>                           11      0.10 / 0.01 / 0.01 / 0.01 / 0.04          
void cudnn::ops::softmax_fw_kernel<2, __half, float, 256, 1, 0, 0>                          11      0.10 / 0.01 / 0.01 / 0.01 / 0.03          
void phi::VectorizedSoftmaxForward<float, float, long, 4, false>                            11      0.09 / 0.01 / 0.01 / 0.01 / 0.03          
void phi::AccuracyCudaKernel<512>                                                           11      0.09 / 0.01 / 0.01 / 0.01 / 0.03          
void splitKreduce_kernel<__half, __half, float, __half>                                     11      0.06 / 0.01 / 0.01 / 0.01 / 0.02          
void splitKreduce_kernel<float, __half, float, __half>                                      11      0.06 / 0.01 / 0.01 / 0.00 / 0.02          
void cub::DeviceReduceSingleTileKernel<cub::DeviceReducePolicy<long, long, int, phi::kp...  11      0.06 / 0.01 / 0.01 / 0.00 / 0.02          
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eige...  11      0.06 / 0.01 / 0.01 / 0.00 / 0.02          
void cub::DeviceReduceSingleTileKernel<cub::DeviceReducePolicy<long, long, int, phi::kp...  11      0.05 / 0.00 / 0.01 / 0.00 / 0.02          
void phi::funcs::VectorizedBroadcastKernel<long, bool, phi::funcs::NotEqualFunctor<long...  11      0.05 / 0.00 / 0.01 / 0.00 / 0.02          
void cub::DeviceReduceSingleTileKernel<cub::DeviceReducePolicy<float, float, int, phi::...  11      0.05 / 0.00 / 0.01 / 0.00 / 0.02          
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eige...  11      0.05 / 0.00 / 0.01 / 0.00 / 0.02          
void phi::funcs::VectorizedBroadcastKernel<float, float, phi::funcs::MultiplyGradFuncto...  11      0.05 / 0.00 / 0.01 / 0.00 / 0.02          
void phi::funcs::VectorizedBroadcastKernel<float, float, phi::funcs::MultiplyFunctor<fl...  11      0.05 / 0.00 / 0.01 / 0.00 / 0.02          
void phi::funcs::VectorizedBroadcastKernel<long, bool, phi::funcs::LessThanFunctor<long...  11      0.05 / 0.00 / 0.00 / 0.00 / 0.02          
void phi::funcs::VectorizedBroadcastKernel<long, long, phi::funcs::MultiplyFunctor<long...  11      0.05 / 0.00 / 0.00 / 0.00 / 0.02          
void phi::SoftmaxWithCrossEntropyGradHardLabel<float, long>                                 11      0.05 / 0.00 / 0.00 / 0.00 / 0.02          
void phi::funcs::VectorizedBroadcastKernel<long, bool, phi::funcs::GreaterEqualFunctor<...  11      0.05 / 0.00 / 0.00 / 0.00 / 0.02          
void cask_cudnn::computeOffsetsKernel<false, false>                                         11      0.05 / 0.00 / 0.00 / 0.00 / 0.02          
void paddle::operators::InverseAndMemset<float>                                             11      0.04 / 0.00 / 0.00 / 0.00 / 0.01          
void phi::funcs::VectorizedElementwiseKernel<long, phi::CastFuctor<bool, long>, 1, 1, 2>    11      0.04 / 0.00 / 0.00 / 0.00 / 0.01          
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eige...  11      0.04 / 0.00 / 0.00 / 0.00 / 0.01          
void phi::MeanRunKernel<float>                                                              11      0.04 / 0.00 / 0.00 / 0.00 / 0.01          
void phi::funcs::VectorizedElementwiseKernel<float, phi::ScaleFunctor<float>, 1, 1, 4>      6       0.03 / 0.00 / 0.00 / 0.00 / 0.01          
------------------------------------------------------------------------------------------  ------  ----------------------------------------  


-------------------------------------------------Memory Manipulation Summary-------------------------------------------------
Time unit: ms
---------------------------------  ------  ----------------------------------------  ----------------------------------------  
Name                               Calls   CPU Total / Avg / Max / Min / Ratio(%)    GPU Total / Avg / Max / Min / Ratio(%)    
---------------------------------  ------  ----------------------------------------  ----------------------------------------  
GpuMemcpySync:GPU->CPU             45      58.98 / 1.31 / 17.88 / 0.02 / 11.26       0.09 / 0.00 / 0.00 / 0.00 / 0.03          
GpuMemcpyAsync:CPU->GPU            66      0.83 / 0.01 / 0.03 / 0.00 / 0.16          0.12 / 0.00 / 0.00 / 0.00 / 0.04          
GpuMemcpyAsync(same_gpu):GPU->GPU  132     2.70 / 0.02 / 0.03 / 0.02 / 0.52          1.95 / 0.01 / 0.02 / 0.00 / 0.65          
GpuMemcpySync:CUDAPinned->GPU      22      16.17 / 0.74 / 1.44 / 0.04 / 3.09         15.30 / 0.70 / 1.40 / 0.00 / 5.08         
GpuMemcpyAsync:GPU->CPU            22      0.60 / 0.03 / 0.04 / 0.02 / 0.12          0.04 / 0.00 / 0.00 / 0.00 / 0.01          
BufferedReader:MemoryCopy          11      40.17 / 3.65 / 3.71 / 3.62 / 7.67         0.00 / 0.00 / 0.00 / 0.00 / 0.00          
---------------------------------  ------  ----------------------------------------  ----------------------------------------  



debug VIT start
debug 1
debug 2
[16, 196, 768]
[1, 1, 768]
[16, 1, 768]
[1, 197, 768]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
=====================profiler step()===============================
debug VIT start
debug 1
debug 2
[16, 196, 768]
[1, 1, 768]
[16, 1, 768]
[1, 197, 768]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
Found inf or nan, current scale is: 8.0, decrease to: 8.0*0.5
=====================profiler step()===============================
debug VIT start
debug 1
debug 2
[16, 196, 768]
[1, 1, 768]
[16, 1, 768]
[1, 197, 768]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
=====================profiler step()===============================
debug VIT start
debug 1
debug 2
[16, 196, 768]
[1, 1, 768]
[16, 1, 768]
[1, 197, 768]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
Found inf or nan, current scale is: 4.0, decrease to: 4.0*0.5
=====================profiler step()===============================
debug VIT start
debug 1
debug 2
[16, 196, 768]
[1, 1, 768]
[16, 1, 768]
[1, 197, 768]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
=====================profiler step()===============================
debug VIT start
debug 1
debug 2
[16, 196, 768]
[1, 1, 768]
[16, 1, 768]
[1, 197, 768]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
[16, 197, 768]
[16, 197, 2304]
<class 'list'>
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 197, 768]
[16, 197, 4, 192]
[16, 4, 197, 192]
[16, 4, 197, 197]
[16, 4, 197, 192]
[16, 197, 768]
Found inf or nan, current scale is: 2.0, decrease to: 2.0*0.5
=====================profiler step()===============================
=====================profiler===============================
============================================Perf Summary============================================
Reader Ratio: 0.057%
Time Unit: s, IPS Unit: steps/s
|                 |       avg       |       max       |       min       |
|   reader_cost   |     0.00016     |     0.00017     |     0.00015     |
|    batch_cost   |     0.27793     |     2.20798     |     0.03882     |
|       ips       |     3.59799     |     25.76092    |     0.45290     |
========exit() python==================
